diff -Nru tensorflow-1.7.0/configure-cscs.sh tensorflow-1.7.0.patched/configure-cscs.sh
--- tensorflow-1.7.0/configure-cscs.sh	1970-01-01 01:00:00.000000000 +0100
+++ tensorflow-1.7.0.patched/configure-cscs.sh	2018-07-17 12:40:04.000000000 +0200
@@ -0,0 +1,34 @@
+#!/bin/bash
+
+sed -i s\@'$GCC_PATH'@"$GCC_PATH"@g third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl
+sed -i s\@'$CRAY_CUDATOOLKIT_DIR'@"$CRAY_CUDATOOLKIT_DIR"@g third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl
+
+sed -i s\@'$GCC_PATH'@"$GCC_PATH"@g third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl
+sed -i s\@'$CRAY_CUDATOOLKIT_DIR'@"$CRAY_CUDATOOLKIT_DIR"@g third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl
+
+CONF_IN="configure.in"+
+
+echo "/opt/python/$PYMAJVER.$PYMINVER.$PYREVVER/bin/python"$PYMAJVER > $CONF_IN
+echo "/opt/python/$PYMAJVER.$PYMINVER.$PYREVVER/lib/python"$PYMAJVER"."$PYMINVER"/site-packages" >> $CONF_IN
+echo "y" >> $CONF_IN # Do you wish to use jemalloc as the malloc implementation? [Y/n] y
+echo "n" >> $CONF_IN # Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
+echo "n" >> $CONF_IN # Do you wish to build TensorFlow with Hadoop File System support? [y/N]
+echo "n" >> $CONF_IN # Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]:
+echo "n" >> $CONF_IN # Do you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]:
+echo "n" >> $CONF_IN # Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]
+echo "n" >> $CONF_IN # Do you wish to build TensorFlow with GDR support? [y/N]:
+echo "n" >> $CONF_IN # Do you wish to build TensorFlow with VERBS support? [y/N]
+echo "n" >> $CONF_IN # Do you wish to build TensorFlow with OpenCL support? [y/N] n
+echo "n" >> $CONF_IN # Do you want CUDA support? [y/N] n
+echo "n" >> $CONF_IN # Do you wish to build TensorFlow with TensorRT support? [y/N] n
+echo "n" >> $CONF_IN # Do you want to use clang as CUDA compiler? [y/N] n
+echo $GCC_PATH"/bin/gcc" >> $CONF_IN # Please specify which gcc should be used by nvcc as the host compiler 
+echo "n" >> $CONF_IN # MPI support?
+echo "-march=native" >> $CONF_IN # Please specify optimization flags "--config=opt" :
+
+
+cat $CONF_IN
+echo "---"
+./configure < $CONF_IN
+
+exit
diff -Nru tensorflow-1.7.0/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl tensorflow-1.7.0.patched/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl
--- tensorflow-1.7.0/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl	2018-03-29 06:18:40.000000000 +0200
+++ tensorflow-1.7.0.patched/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl	2018-07-17 12:34:51.000000000 +0200
@@ -46,11 +46,14 @@
 import pipes
 
 # Template values set by cuda_autoconf.
-CPU_COMPILER = ('%{cpu_compiler}')
-GCC_HOST_COMPILER_PATH = ('%{gcc_host_compiler_path}')
+CPU_COMPILER = ('$GCC_PATH/snos/bin/gcc')
+GCC_HOST_COMPILER_PATH = ('$GCC_PATH/snos/bin/gcc')
 
-NVCC_PATH = '%{nvcc_path}'
-PREFIX_DIR = os.path.dirname(GCC_HOST_COMPILER_PATH)
+CURRENT_DIR = os.path.dirname(sys.argv[0])
+NVCC_PATH = ('$CRAY_CUDATOOLKIT_DIR/bin/nvcc')
+LLVM_HOST_COMPILER_PATH = ('$GCC_PATH/snos/bin/gcc')
+AS_PATH = ('/usr/bin/as')
+PREFIX_DIR = os.path.dirname(AS_PATH)
 NVCC_VERSION = '%{cuda_version}'
 
 def Log(s):
@@ -194,7 +197,8 @@
   srcs = ' '.join(src_files)
   out = ' -o ' + out_file[0]
 
-  supported_cuda_compute_capabilities = [ %{cuda_compute_capabilities} ]
+  #supported_cuda_compute_capabilities = [ %{cuda_compute_capabilities} ]
+  supported_cuda_compute_capabilities = ["6.0",]
   nvccopts = '-D_FORCE_INLINES '
   for capability in supported_cuda_compute_capabilities:
     capability = capability.replace('.', '')
diff -Nru tensorflow-1.7.0/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl tensorflow-1.7.0.patched/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl
--- tensorflow-1.7.0/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl	2018-03-29 06:18:40.000000000 +0200
+++ tensorflow-1.7.0.patched/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl	2018-07-17 12:35:13.000000000 +0200
@@ -44,7 +44,7 @@
 
   tool_path { name: "ar" path: "/usr/bin/ar" }
   tool_path { name: "compat-ld" path: "/usr/bin/ld" }
-  tool_path { name: "cpp" path: "/usr/bin/cpp" }
+  tool_path { name: "cpp" path: "$GCC_PATH/snos/bin/cpp" }
   tool_path { name: "dwp" path: "/usr/bin/dwp" }
   # As part of the TensorFlow release, we place some cuda-related compilation
   # files in @local_config_cuda//crosstool/clang/bin, and this relative
@@ -59,7 +59,12 @@
   linker_flag: "-B/usr/bin/"
 
 %{host_compiler_includes}
-  tool_path { name: "gcov" path: "/usr/bin/gcov" }
+  tool_path { name: "gcov" path: "$GCC_PATH/snos/bin/gcov" }
+
+  cxx_builtin_include_directory: "$GCC_PATH/snos/include"
+  cxx_builtin_include_directory: "$GCC_PATH/snos/lib/gcc/x86_64-suse-linux/default/include-fixed/"
+  cxx_builtin_include_directory: "$GCC_PATH/snos/lib/gcc/x86_64-suse-linux/default/include/"
+  cxx_builtin_include_directory: "$CRAY_CUDATOOLKIT_DIR/include/"
 
   # C(++) compiles invoke the compiler (as that is the one knowing where
   # to find libraries), but we provide LD so other rules can invoke the linker.
@@ -119,6 +124,7 @@
   # Gold linker only? Can we enable this by default?
   # linker_flag: "-Wl,--warn-execstack"
   # linker_flag: "-Wl,--detect-odr-violations"
+  linker_flag: "-Wl,-rpath,$GCC_PATH/snos/lib64/"
 
   # Include directory for cuda headers.
 %{cuda_include_path}
